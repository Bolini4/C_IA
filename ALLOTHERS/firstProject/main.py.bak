from keras.datasets import mnist

from keras.models import Sequential
from keras.layers import Dense
import matplotlib
matplotlib.use('tkAgg')
import matplotlib.pyplot as plt

import numpy as np

samples = 100

# Load the MNIST dataset
data = mnist.load_data()

print(type(data))

#Data is a tuple of two tuples, each containing two numpy arrays
#The firtst tuple is for training and the second for test

#Xtrain (60000, 28, 28) 60000 images of 28x28 pixels
#Xtest (10000, 28, 28) 10000 images of 28x28 pixels

((X_train, y_train), (X_test, y_test)) = data

X_train_subset = X_train[:samples]
y_train_subset = y_train[:samples]

print(X_train.shape)

#Each image is a 28x28 pixel -> Numpy array of shape(28, 28)

X_train = X_train.reshape((X_train.shape[0], 28*28)).astype('float32')
X_test = X_test.reshape((X_test.shape[0], 28*28)).astype('float32')

X_train = X_train / 255
X_test = X_test / 255


#Import the model

model = Sequential()

model.add(Dense(32,input_dim = 28 * 28, activation='relu'))
model.add(Dense(64,activation='relu'))
model.add(Dense(10, activation='softmax'))

model.summary()
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(epochs=2,batch_size=100, x=X_train, y=y_train, validation_data=(X_test, y_test))

scores = model.evaluate(X_test, y_test)
print(scores)
print('Accuracy: {}'.format(scores[1]))

# # Affichage de l'historique de la précision
# plt.plot(history.history['accuracy'], label='Training Accuracy')
# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
# plt.title('Training and Validation Accuracy')
# plt.xlabel('Epoch')
# plt.ylabel('Accuracy')
# plt.legend()
# plt.show()

# # Affichage de l'historique de la perte
# plt.plot(history.history['loss'], label='Training Loss')
# plt.plot(history.history['val_loss'], label='Validation Loss')
# plt.title('Training and Validation Loss')
# plt.xlabel('Epoch')
# plt.ylabel('Loss')
# plt.legend()
# plt.show()



# Fonction pour afficher une grille d'images
def plot_images(images, labels, nrows, ncols):
    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 10))
    for i, ax in enumerate(axes.flat):
        ax.imshow(images[i].reshape(28, 28), cmap='gray')
        ax.set_title(f"Label: {labels[i]}")
        ax.axis('off')
    plt.tight_layout()
    plt.show()

# Afficher une grille d'images d'entraînement
plot_images(X_train_subset, y_train_subset, 5, 5)


# def plot1image(images,labels,number):
#     plt.imshow(images[number].reshape(28, 28), cmap='gray')
#     plt.title(f"Label: {labels[number]}")
#     plt.show()

# plot1image(X_train_subset,y_train,0)


x_test_preprocessed = X_train_subset.reshape((X_train_subset.shape[0], 28*28)).astype('float32') / 255

# Utiliser la méthode predict() pour obtenir les probabilités de classe
predicted_probabilities = model.predict(x_test_preprocessed)

# Extraire la classe prédite pour chaque exemple
predicted_classes = np.argmax(predicted_probabilities, axis=1)

# Afficher chaque label et sa prédiction correspondante
for i in range(len(y_train_subset)):
    print("Label réel:", y_train_subset[i], "- Prédiction:", predicted_classes[i])